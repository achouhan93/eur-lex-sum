{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# Extraction of the Summary for Celex Number Documents from Eur-lex website and store it in Elastic Search (Localhost) or OpenSearch (UniHeidelberg)\n",
    "# \n",
    "# Code will:\n",
    "# 1. Extract the list of CELEX Numbers from the \"provided URL\"\n",
    "#    \"provided_URl\": Legal Acts for Energy Domain (https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile)\n",
    "#\n",
    "# 2. For the Languages Tweaked in the code\n",
    "#   2a. Extract the Summary Information for the Celex Numbers (Raw HTML and Document Content)\n",
    "#   2b. Extract the Content of the Celex Document (Raw HTML and Document Content)\n",
    "#\n",
    "# Features:\n",
    "# Code is customised for:\n",
    "# 1. Any domain of legal acts from EUR-LEX website (https://eur-lex.europa.eu/browse/directories/legislation.html)\n",
    "# 2. Any Language\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all requried packages\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from time import sleep, time\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# For Uni Heidelberg Server\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "# For Localhost\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################################################################################################\n",
    "# Directory Creation\n",
    "# For logging the progress of the script and the list of Celex Numbers extracted\n",
    "#####################################################################################################\n",
    "working_dir = os.getcwd()   \n",
    "directory = os.path.join(working_dir, 'Scrapped_Data')\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "filename_celex = os.path.join(directory, 'Celex_Numbers.csv')\n",
    "\n",
    "# Preparing a File to Log the Metadata Informaiton\n",
    "extraction_logs = os.path.join(directory, 'Logs_Extracting_MetaData.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celex Number Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages_extraction(provided_url):\n",
    "    \"\"\"\n",
    "    Function extracts the number of pages that needs to be considered for extracting the Celex Numbers\n",
    "\n",
    "    Args:\n",
    "        provided_url (string): URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "                                Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "                                Energy Legal Acts: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "\n",
    "    Returns:\n",
    "        integer: Value of the number of pages present in the provided URL\n",
    "    \"\"\"\n",
    "\n",
    "    input_url = urllib.request.urlopen(provided_url)\n",
    "    input_soup = BeautifulSoup(input_url , 'lxml')\n",
    "    page_number_indexes = input_soup.find_all('a', class_ = 'btn btn-primary btn-sm')\n",
    "    last_page_number_url = page_number_indexes[1].attrs['href']\n",
    "    last_page_number = int((re.search('page=(\\d+)', last_page_number_url , re.IGNORECASE)).group(1)) + 1\n",
    "    sleep(1)\n",
    "    return last_page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_celex(pages, provided_url):\n",
    "    \"\"\"\n",
    "    Function extracts all the Celex Number from the provided URL\n",
    "\n",
    "    Args:\n",
    "        pages (integer): The value of number of pages that needs to be considered for extracting the Celex Numbers\n",
    "        provided_url (string): URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "                                Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "                                Energy Legal Acts: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "\n",
    "    Returns:\n",
    "        list: List of Celex Number extracted from the provided URL\n",
    "    \"\"\"    \n",
    "    list_celex = []\n",
    "    print(f'Total Number of Pages present in the provided URL: {pages - 1}')\n",
    "    while True:\n",
    "        page_number = input('Number of Pages that needs to be considered for Document Extraction: ')\n",
    "        pages_considered = int(page_number) + 1\n",
    "        if pages_considered > pages:\n",
    "            print(\"Number of pages entered is greater than the toal number of pages present. Kindly enter the value within range\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    for i in range(1, pages_considered):\n",
    "        # Reading particular URL information\n",
    "        sleep(1)\n",
    "        url = urllib.request.urlopen(provided_url + '&page=' +str(i)).read()\n",
    "\n",
    "        # Scrapping the Page\n",
    "        soup = BeautifulSoup(url , 'lxml')\n",
    "\n",
    "        # Fetching celex numbers by parsing html tags heirarchy and checking for text 'CELEX number'. \n",
    "        try:\n",
    "            div_tags = soup.find_all(\"div\", attrs={\"class\": \"col-sm-6\"})\n",
    "            for tag in div_tags:\n",
    "                titles = tag.find_all(\"dt\")\n",
    "                values = tag.find_all(\"dd\")\n",
    "                for t ,v in zip(titles, values):\n",
    "                    if t.text == 'CELEX number: ':\n",
    "                        list_celex.append(v.text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Saving all the CELEX Numbers into CSV File (For further scarpping)\n",
    "    pd.DataFrame(list_celex, columns=['celex_id']).to_csv(filename_celex, index = False)\n",
    "\n",
    "    return list_celex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celex_main(provided_url):\n",
    "    \"\"\"\n",
    "    Orchestrator function to extract the list of Celex Numbers from the provided URL\n",
    "\n",
    "    Args:\n",
    "        provided_url (string): URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "                                Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "                                Energy Legal Acts: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "\n",
    "    Returns:\n",
    "        list: List of Celex numbers extracted from the provided URL\n",
    "    \"\"\"\n",
    "    logging.info(\"Execution of Extraction of Celex Number - Started\")\n",
    "\n",
    "    last_page_number = pages_extraction(provided_url)\n",
    "    all_celex_number = get_celex(last_page_number, provided_url)\n",
    "    \n",
    "    logging.info(\"Execution of Extraction of Celex Number - Ended\")\n",
    "    return all_celex_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celex Number Document Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_content(celex_id, lang):\n",
    "    \"\"\"\n",
    "    Function to extract the Content of the Celex document in the provided language\n",
    "\n",
    "    Args:\n",
    "        celexId (string): Celex number whose content needs to be extracted\n",
    "        lang (string): Language of the Celex document\n",
    "    \n",
    "    Returns:\n",
    "        dictionary: Raw HTML of the Celex document\n",
    "                    Content of the Celex document\n",
    "    \"\"\"\n",
    "    # Dictonary to save info for each iteration\n",
    "    content_dict = {}\n",
    "\n",
    "    # Tracking dictonary which type of document (HTML / PDF / NONE) in each language\n",
    "    tracking_dict = {}\n",
    "    tracking_dict['celex_id'] = celex_id\n",
    "\n",
    "########################################################################################################\n",
    "    # Preparing URLs based on given number & Language.\n",
    "    url_html = f'https://eur-lex.europa.eu/legal-content/{lang}/TXT/HTML/?uri=CELEX:{celex_id}'\n",
    "    url_pdf = f'https://eur-lex.europa.eu/legal-content/{lang}/TXT/PDF/?uri=CELEX:{celex_id}'\n",
    "########################################################################################################\n",
    "    try:\n",
    "        # First try to get HTML information\n",
    "        content_html = requests.get(url_html).text\n",
    "        if 'The requested document does not exist.' in content_html:\n",
    "            # If there is no HTML available, then try to get PDF info.\n",
    "            content_pdf = requests.get(url_pdf)\n",
    "        \n",
    "            if 'The requested document does not exist.' in content_pdf.text:\n",
    "                # If PDF is also not available , then Raise Exception.\n",
    "                raise Exception\n",
    "            \n",
    "            document = \"NA\"\n",
    "            document_content = content_pdf.content\n",
    "            tracking_dict[lang] = \"PDF\"\n",
    "        else:\n",
    "            # Saving HTML File (if available)\n",
    "            if \"docHtml\" in content_html:\n",
    "                content_html_text = BeautifulSoup(content_html, \"html.parser\").find(\"div\", {\"id\": \"docHtml\"})\n",
    "                document_content = content_html_text.text\n",
    "                document = content_html\n",
    "            else:\n",
    "                content_html_text = BeautifulSoup(content_html, \"html.parser\")\n",
    "                document_content = content_html_text.text\n",
    "                document = content_html\n",
    "            \n",
    "            tracking_dict[lang] = \"HTML\"\n",
    "\n",
    "        content_dict['rawDocument'] = document\n",
    "        content_dict['documentContent'] = document_content\n",
    "\n",
    "    except :\n",
    "        tracking_dict[lang] = \"None\"\n",
    "        content_dict['rawDocument'] = \"NA\"\n",
    "        content_dict['documentContent'] = \"NA\"\n",
    "    \n",
    "    logging.info(tracking_dict)\n",
    "    sleep(1)\n",
    "\n",
    "    return content_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_summary(lang, document_page):\n",
    "    \"\"\"\n",
    "    Function extracts the summary of the Celex document\n",
    "\n",
    "    Args:\n",
    "        lang (string): Language of the summary that needs to be extracted\n",
    "        document_page (string): Summary HTML page of the document\n",
    "\n",
    "    Returns:\n",
    "        dictionary: Raw HTML of the Summary in the provided language\n",
    "                    Summary content of the document in the provided language\n",
    "    \"\"\"\n",
    "    summary_dict = {}\n",
    "    language_id = f'format_language_table_HTML_{lang}'\n",
    "    list_of_documents = document_page.find( 'a', attrs={'id':language_id, 'class': 'piwik_download'}, href = True)\n",
    "    summary_url = 'https://eur-lex.europa.eu/'+ list_of_documents['href'][list_of_documents['href'].find(\"legal-content\"):]\n",
    "    \n",
    "    summary_html = requests.get(summary_url).text\n",
    "    summary_dict['rawSummary'] = summary_html\n",
    "    summary_dict['summaryContent']= BeautifulSoup(summary_dict['rawSummary'], \"html.parser\").text\n",
    "\n",
    "    return summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_information(celex_list):\n",
    "    \"\"\"\n",
    "    Orchestrator functioin to extract the summary and document content for the provided Celex Number\n",
    "\n",
    "    Args:\n",
    "        celex_list (list): List of Celex number for which the summary and contents needs to be extracted\n",
    "\n",
    "    Returns:\n",
    "        list: Comprising of dictionary of information about the summary and document \n",
    "                content for the provided Celex Numbers in the different languages\n",
    "    \"\"\"\n",
    "    # langs = ['BG' , 'CS' , 'DA' , 'DE' ,  'EL' , 'EN' , 'ES' , \n",
    "    #      'ET' , 'FI' , 'FR' , 'GA' , 'HR' , 'HU' , 'IT' ,\n",
    "    #       'LT' , 'LV' , 'MT' , 'NL', 'PL' , 'PT' , 'RO' , \n",
    "    #       'SK' , 'SL' , 'SV']\n",
    "    langs = ['EN', 'DE']\n",
    "    \n",
    "    details = []\n",
    "    logging.info(\"Execution of Extraction of Summary for respective Celex Document - Started\")\n",
    "\n",
    "    # For Each CELEX_Number preparing the URL and extracting Info from Website\n",
    "    for celex_id in celex_list:\n",
    "        celex_document_information = {}\n",
    "        celex_document_information['_id'] = celex_id\n",
    "        \n",
    "        for lang in langs:\n",
    "            language_document_information = {}\n",
    "            summary_data = {}\n",
    "            raw_data = {}\n",
    "\n",
    "            # Preparing URL for the summary of the Celex number\n",
    "            document_url = f'https://eur-lex.europa.eu/legal-content/{lang}/LSU/?uri=CELEX:{celex_id}'\n",
    "            document_request = requests.get(document_url)\n",
    "\n",
    "            if 'No legislative summaries' in document_request.text:\n",
    "                summary_data['rawSummary'] = 'NA'\n",
    "                summary_data['summaryContent'] = 'NA'\n",
    "            else:\n",
    "                # HTML for that information\n",
    "                document_page = BeautifulSoup(document_request.text, \"html.parser\")\n",
    "                summary_data = get_document_summary(lang, document_page)    \n",
    "            \n",
    "            language_document_information['summaryInformation'] = summary_data\n",
    "\n",
    "            raw_data = get_document_content(celex_id, lang)\n",
    "            language_document_information['documentInformation'] = raw_data\n",
    "\n",
    "            celex_document_information[lang] = language_document_information\n",
    "\n",
    "            logging.info(f'Completed Extracting Information of {celex_id} for {lang}')\n",
    "            sleep(1)\n",
    "\n",
    "        details.append(celex_document_information)\n",
    "        logging.info(\"Execution of Extraction of Summary for respective Celex Document - Ended\")\n",
    "        \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_mapping():\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Creation of the mapping for the ElasticSearch or OpenSearch Index\n",
    "    # \n",
    "    # For this project mapping is created from JSON using https://json-to-es-mapping.netlify.app/\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       No input is required for this function, as it is executed to create an object for mapping\n",
    "    # \n",
    "    #  Output:\n",
    "    #       esMapping: Mapping setting for the ElasticSearch or OpenSearch Index\n",
    "    # \"\"\"\"\"\"\"\"\"\" \n",
    "    es_mapping = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\":1,\n",
    "            \"number_of_replicas\":0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"english\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"documentInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawDocument\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"documentContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"summaryInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawSummary\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"summaryContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"german\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"documentInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawDocument\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"documentContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"summaryInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawSummary\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"summaryContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return es_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_create(es_index, index_name, es_mapping):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Creation of the Index if not present in the cluster\n",
    "    # \n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       esIndex: ElasticSearch or OpenSearch connection\n",
    "    #       indexName: Name of the index that needs to be created\n",
    "    #       esMapping: Mapping of the index that needs to be created\n",
    "    # \n",
    "    #  Output:\n",
    "    #       If the index is already present then the function wont take any action\n",
    "    #       And if the index is not present then it will be created by the function\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    search_index = es_index.indices.exists(index=index_name)\n",
    "\n",
    "    if search_index == False:\n",
    "        es_index.indices.create(index=index_name, ignore=[400,404], body=es_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_insert(es_index, index_name, celex_information):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Insert the document in the ElasticSearch or OpenSearch Index\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       esIndex: ElasticSearch or OpenSearch connection\n",
    "    #       indexName: Name of the index that needs to be created\n",
    "    #       celexInformation: Information that needs to be inserted in the Index in JSON format\n",
    "    # \n",
    "    #  Output:\n",
    "    #       Insert the information in the ElasticSearch or OpenSearch Index keeping unqiue ID (_id) as the celex number\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    for id in range(len(celex_information)):\n",
    "        doc = { \n",
    "                \"english\":\n",
    "                { \n",
    "                    \"documentInformation\":\n",
    "                        {\n",
    "                            \"rawDocument\":celex_information[id]['EN']['documentInformation']['rawDocument'],\n",
    "                            \"documentContent\":celex_information[id]['EN']['documentInformation']['documentContent']\n",
    "                        },\n",
    "\n",
    "                    \"summaryInformation\":\n",
    "                        {\n",
    "                            \"rawSummary\":celex_information[id]['EN']['summaryInformation']['rawSummary'],\n",
    "                            \"summaryContent\":celex_information[id]['EN']['summaryInformation']['summaryContent']\n",
    "                        }\n",
    "                },\n",
    "                \"german\":\n",
    "                { \n",
    "                    \"documentInformation\":\n",
    "                        {\n",
    "                            \"rawDocument\":celex_information[id]['DE']['documentInformation']['rawDocument'],\n",
    "                            \"documentContent\":celex_information[id]['DE']['documentInformation']['documentContent']\n",
    "                        },\n",
    "\n",
    "                    \"summaryInformation\":\n",
    "                        {\n",
    "                            \"rawSummary\":celex_information[id]['DE']['summaryInformation']['rawSummary'],\n",
    "                            \"summaryContent\":celex_information[id]['DE']['summaryInformation']['summaryContent']\n",
    "                        }\n",
    "                }\n",
    "            }\n",
    "        _id = celex_information[id]['_id']\n",
    "        \n",
    "        retries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                es_index.index(index=index_name,body=doc,id=_id)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if retries == 5:\n",
    "                    print('Indexing user \\'{}\\' failed for 5 consecutiv times. Aborting!'.format(_id))\n",
    "                    break\n",
    "                retries += 1\n",
    "                sleep(retries * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_existing_check(es_index, index_name, celex_list):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Check if the document is already present in the index\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       esIndex: ElasticSearch or OpenSearch connection\n",
    "    #       indexName: Name of the index that needs to be created\n",
    "    #       celexList: List of the celex number for which the summary and content needs to be extracted\n",
    "    # \n",
    "    #  Output:\n",
    "    #       nonExisting: List of all the celex number that are not present in the ElasticSearch or OpenSearch index\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    non_existing = []\n",
    "    for celex_id in celex_list:\n",
    "        document_status = es_index.exists(index= index_name, id= celex_id)\n",
    "        if document_status == False:\n",
    "            non_existing.append(celex_id)\n",
    "    \n",
    "    return non_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-056c83cee77d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Instance of Elastic Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Server of the Elastic Search Index (localhost or Uniheidelberg): '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'localhost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m9200\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Configuring the File name to logging Level\n",
    "    logging.basicConfig(filename=extraction_logs,level=logging.INFO)\n",
    "\n",
    "    list_celex_number = pd.DataFrame(data=None)\n",
    "    celex_information = pd.DataFrame(data=None)\n",
    "\n",
    "    # Input from the User:\n",
    "    # URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "    # For Example:\n",
    "    #   1. From Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "    #   2. If Legal Acts for Energy Domain is required\n",
    "    #   3. Provided URl will be: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "\n",
    "    provided_url = input('Provide the URL: ')\n",
    "\n",
    "    start_time = time()\n",
    "    logging.info(\"Current date and time: \" + str(start_time))\n",
    "\n",
    "    # Elastic Search Index\n",
    "    index_name = input('Provide the Elastic Search Index Name: ')\n",
    "\n",
    "    while True:  \n",
    "        # Instance of Elastic Search\n",
    "        server = input('Server of the Elastic Search Index (localhost or Uniheidelberg): ')\n",
    "        if server.lower() == \"localhost\":\n",
    "            es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "            break\n",
    "        elif server.lower() == \"uniheidelberg\":\n",
    "            user_name = input('University Heidelberg Elastic Search Username: ')\n",
    "            password = input('University Heidelberg Elastic Search Password: ')\n",
    "            es = OpenSearch(hosts = [{'host': 'elastic-dbs.ifi.uni-heidelberg.de', 'port': 443}], \n",
    "            http_auth =(user_name, password), \n",
    "            use_ssl = True,\n",
    "            verify_certs = True,\n",
    "            ssl_assert_hostname = False,\n",
    "            ssl_show_warn = False\n",
    "            )\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    es_index_mapping = elastic_search_mapping()\n",
    "    elastic_search_create(es, index_name, es_index_mapping)\n",
    "    \n",
    "    # Calling the Function for the given CELEX_Numbers\n",
    "    list_celex_number = celex_main(provided_url)\n",
    "\n",
    "    non_existing_celex_number = elastic_search_existing_check(es, index_name, list_celex_number)\n",
    "\n",
    "    # Calling the Function to extract the metadata for the list of celex numbers\n",
    "    celex_information = get_document_information(non_existing_celex_number)\n",
    "\n",
    "    elastic_search_insert(es, index_name, celex_information)\n",
    "\n",
    "    end_time = time()\n",
    "    logging.info(\"Current date and time: \" + str(end_time))\n",
    "    logging.info(\"Time for Execution of Script: \" + str(start_time - end_time))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
