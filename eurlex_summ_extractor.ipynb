{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# Extraction of the Summary for Celex Number Documents from Eur-lex website and store it in Elastic Search (Localhost) or OpenSearch (UniHeidelberg)\n",
    "# \n",
    "# Code will:\n",
    "# 1. Extract the list of CELEX Numbers from the \"provided URL\"\n",
    "#    \"provided_URl\": Legal Acts for Energy Domain (https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile)\n",
    "#\n",
    "# 2. For the Languages Tweaked in the code\n",
    "#   2a. Extract the Summary Information for the Celex Numbers (Raw HTML and Document Content)\n",
    "#   2b. Extract the Content of the Celex Document (Raw HTML and Document Content)\n",
    "#\n",
    "# Features:\n",
    "# Code is customised for:\n",
    "# 1. Any domain of legal acts from EUR-LEX website (https://eur-lex.europa.eu/browse/directories/legislation.html)\n",
    "# 2. Any Language\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all requried packages\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import requests\n",
    "from time import sleep, time\n",
    "\n",
    "# For Uni Heidelberg Server\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "# For Localhost\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "# Directory Creation\n",
    "# For logging the progress of the script and the list of Celex Numbers extracted\n",
    "#####################################################################################################\n",
    "working_dir = os.getcwd()   \n",
    "directory = os.path.join(working_dir, 'Scrapped_Data')\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "filename_celex = os.path.join(directory, 'Celex_Numbers.csv')\n",
    "\n",
    "# Preparing a File to Log the Metadata Informaiton\n",
    "extraction_logs = os.path.join(directory, 'Logs_Extracting_MetaData.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celex Number Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages(provided_url):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: It extracts the number of pages that needs to be considered for extracting the Celex Numbers\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       provided_url: URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "    #                     Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "    #                     Energy Legal Acts: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "    # \n",
    "    #  Output:\n",
    "    #       last_page_number: Value of the number of pages present in the provided URL\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    input_url = urllib.request.urlopen(provided_url)\n",
    "    input_soup = BeautifulSoup(input_url , 'lxml')\n",
    "    page_number_indexes = input_soup.find_all('a', class_ = 'btn btn-primary btn-sm')\n",
    "    last_page_number_url = page_number_indexes[1].attrs['href']\n",
    "    last_page_number = int((re.search('page=(\\d+)', last_page_number_url , re.IGNORECASE)).group(1)) + 1\n",
    "    return last_page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_celex(pages, provided_url):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: It extracts all the Celex Number from the provided URL.\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       pages: The value of number of pageas that needs to be considered for extracting the Celex Numbers.\n",
    "    #       provided_url: URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "    #                     Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "    #                     Energy Legal Acts: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "    #\n",
    "    #  Output:\n",
    "    #       CELEX_Numbers: List of Celex Number extracted from the provided URL\n",
    "    # \"\"\"\"\"\"\"\"\"\"  \n",
    "    CELEX_Numbers = []\n",
    "    print(f'Total Number of Pages present in the provided URL: {pages - 1}')\n",
    "    while True:\n",
    "        page_number = input('Number of Pages that needs to be considered for Document Extraction: ')\n",
    "        pages_considered = int(page_number) + 1\n",
    "        if pages_considered > pages:\n",
    "            print(\"Number of pages entered is greater than the toal number of pageas present\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    for i in range(1, pages_considered):\n",
    "        # Reading particular URL information\n",
    "        sleep(1)\n",
    "        url = urllib.request.urlopen(provided_url + '&page=' +str(i)).read()\n",
    "        \n",
    "        # Scrapping the Page\n",
    "        soup = BeautifulSoup(url , 'lxml')\n",
    "\n",
    "        # Fetching celex numbers by parsing html tags heirarchy and checking for text 'CELEX number'. \n",
    "        try:\n",
    "            t = soup.find_all(\"div\", attrs={\"class\": \"col-sm-6\"})\n",
    "            for tag in t:\n",
    "                titles = tag.find_all(\"dt\")\n",
    "                values = tag.find_all(\"dd\")\n",
    "                for t ,v in zip(titles, values):\n",
    "                    if t.text == 'CELEX number: ':\n",
    "                        CELEX_Numbers.append(v.text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Saving all the CELEX Numbers into CSV File (For further scarpping)\n",
    "    pd.DataFrame(CELEX_Numbers, columns=['celex_id']).to_csv(filename_celex, index = False)\n",
    "\n",
    "    return CELEX_Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celex_main(provided_url):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: It is an Orchestrator function that extract the number of pages that needs to be scrapped,\n",
    "    #                and extract the Celex Number from the provided URL\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       provided_url: URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "    #                     Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "    #                     Energy Legal Acts: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "    # \n",
    "    #  Output:\n",
    "    #       all_celex_number: List of all Celex Numbers present in the provided URL\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    logging.info(\"Execution of Extraction of Celex Number - Started\")\n",
    "\n",
    "    last_page_number = pages(provided_url)\n",
    "    all_celex_number = get_celex(last_page_number, provided_url)\n",
    "    \n",
    "    logging.info(\"Execution of Extraction of Celex Number - Ended\")\n",
    "    return all_celex_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celex Number Document Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_content(celex_id , lang):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Extract the content present in the Celex document\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       celex_id: Celex Number whose content needs to be extracted\n",
    "    #       lang: Language of the Celex document\n",
    "    # \n",
    "    #  Output:\n",
    "    #       dict: Dictionary comprising of:\n",
    "    #               1. HTML raw text of the document\n",
    "    #               2. Content of the document\n",
    "    # \"\"\"\"\"\"\"\"\"\" \n",
    "\n",
    "    # Dictonary to save info for each iteration\n",
    "    contentDict = {}\n",
    "\n",
    "    # Tracking dictonary which type of document (HTML / PDF / NONE) in each language\n",
    "    trackingDict = {}\n",
    "    trackingDict['celex_id'] = celex_id  \n",
    "\n",
    "########################################################################################################\n",
    "    # Preparing URLs based on given number & Language.\n",
    "    urlHTML = f'https://eur-lex.europa.eu/legal-content/{lang}/TXT/HTML/?uri=CELEX:{celex_id}'\n",
    "    urlPDF = f'https://eur-lex.europa.eu/legal-content/{lang}/TXT/PDF/?uri=CELEX:{celex_id}'\n",
    "########################################################################################################\n",
    "    try:\n",
    "        # First try to get HTML information\n",
    "        contentHTML = requests.get(urlHTML).text\n",
    "        if 'The requested document does not exist.' in contentHTML:\n",
    "            pass\n",
    "            # If there is no HTML available, then try to get PDF info.\n",
    "            contentPDF = requests.get(urlPDF)\n",
    "        \n",
    "            if 'The requested document does not exist.' in contentPDF.text:\n",
    "                # If PDF is also not available , then Raise Exception.\n",
    "                raise Exception\n",
    "            \n",
    "            document = \"NA\"\n",
    "            documentContent = contentPDF.content\n",
    "            trackingDict[lang] = \"PDF\"\n",
    "        else:\n",
    "            # Saving HTML File (if available)\n",
    "            if \"docHtml\" in contentHTML:\n",
    "                contentHTMLText = BeautifulSoup(contentHTML, \"html.parser\").find(\"div\", {\"id\": \"docHtml\"})\n",
    "                documentContent = contentHTMLText.text\n",
    "                document = contentHTML\n",
    "            else:\n",
    "                contentHTMLText = BeautifulSoup(contentHTML, \"html.parser\")\n",
    "                documentContent = contentHTMLText.text\n",
    "                document = contentHTML\n",
    "            \n",
    "            trackingDict[lang] = \"HTML\"\n",
    "\n",
    "        contentDict['rawDocument'] = document\n",
    "        contentDict['documentContent'] = documentContent\n",
    "\n",
    "    except :\n",
    "        trackingDict[lang] = \"None\"\n",
    "        contentDict['rawDocument'] = \"NA\"\n",
    "        contentDict['documentContent'] = \"NA\"\n",
    "    \n",
    "    logging.info(trackingDict)\n",
    "    sleep(2)\n",
    "\n",
    "    return contentDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_summary(lang, documentPage):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Extract the summary content of the Celex document\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       documentPage: Summary HTML page of the Celex Document\n",
    "    #       lang: Language of the Celex document\n",
    "    # \n",
    "    #  Output:\n",
    "    #       dict: Dictionary comprising of:\n",
    "    #               1. HTML summary raw text of the document in the provided language\n",
    "    #               2. Content of the document in the provided language\n",
    "    # \"\"\"\"\"\"\"\"\"\" \n",
    "    summaryDict = {}\n",
    "    languageId = f'format_language_table_HTML_{lang}'\n",
    "    list_of_documents = documentPage.find( 'a', attrs={'id':languageId, 'class': 'piwik_download'}, href = True)\n",
    "    summaryURL = 'https://eur-lex.europa.eu/'+ list_of_documents['href'][list_of_documents['href'].find(\"legal-content\"):]\n",
    "    \n",
    "    summaryHTML = requests.get(summaryURL).text\n",
    "    summaryDict['rawSummary'] = summaryHTML\n",
    "    summaryDict['summaryContent']= BeautifulSoup(summaryDict['rawSummary'], \"html.parser\").text\n",
    "\n",
    "    return summaryDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_information(celexList):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Extracting the summary and content of the Celex document from the Eur-lex website\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       celexList: List of Celex Number whose information needs to be extracted\n",
    "    # \n",
    "    #  Output:\n",
    "    #       details: Summary Content and Document Content of the Celex Document from the Eur-lex website\n",
    "    # \"\"\"\"\"\"\"\"\"\" \n",
    "    # langs = ['BG' , 'CS' , 'DA' , 'DE' ,  'EL' , 'EN' , 'ES' , \n",
    "    #      'ET' , 'FI' , 'FR' , 'GA' , 'HR' , 'HU' , 'IT' ,\n",
    "    #       'LT' , 'LV' , 'MT' , 'NL', 'PL' , 'PT' , 'RO' , \n",
    "    #       'SK' , 'SL' , 'SV']\n",
    "    langs = ['EN', 'DE']\n",
    "    \n",
    "    details = []\n",
    "    logging.info(\"Execution of Extraction of Metadata for respective Celex Document - Started\")\n",
    "\n",
    "    # For Each CELEX_Number preparing the URL and extracting Info from Website\n",
    "    for celexId in celexList:\n",
    "        celexDocumentInformation = {}\n",
    "        celexDocumentInformation['_id'] = celexId\n",
    "        \n",
    "        for lang in langs:\n",
    "            languageDocumentInformation = {}\n",
    "            \n",
    "            # Preparing URL for that CELEX_Number\n",
    "            documentUrl = f'https://eur-lex.europa.eu/legal-content/{lang}/LSU/?uri=CELEX:{celexId}'\n",
    "            r = requests.get(documentUrl)\n",
    "\n",
    "            if 'No legislative summaries' in r.text:\n",
    "                summaryData['rawSummary'] = 'NA'\n",
    "                summaryData['summaryContent'] = 'NA'\n",
    "            else:\n",
    "                # HTML for that information\n",
    "                documentPage = BeautifulSoup(r.text, \"html.parser\")\n",
    "                summaryData = get_document_summary(lang, documentPage)    \n",
    "            \n",
    "            languageDocumentInformation['summaryInformation'] = summaryData\n",
    "\n",
    "            rawData = get_document_content(celexId, lang)\n",
    "            languageDocumentInformation['documentInformation'] = rawData\n",
    "\n",
    "            celexDocumentInformation[lang] = languageDocumentInformation\n",
    "\n",
    "            logging.info(\" Completed Extracting MetaData Information for : \" + str(celexId))\n",
    "            sleep(2)\n",
    "\n",
    "        details.append(celexDocumentInformation)\n",
    "        logging.info(\"Execution of Extraction of Metadata for respective Celex Document - Ended\")\n",
    "        \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_mapping():\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Creation of the mapping for the ElasticSearch or OpenSearch Index\n",
    "    # \n",
    "    # For this project mapping is created from JSON using https://json-to-es-mapping.netlify.app/\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       No input is required for this function, as it is executed to create an object for mapping\n",
    "    # \n",
    "    #  Output:\n",
    "    #       esMapping: Mapping setting for the ElasticSearch or OpenSearch Index\n",
    "    # \"\"\"\"\"\"\"\"\"\" \n",
    "    esMapping = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\":1,\n",
    "            \"number_of_replicas\":0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"english\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"documentInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawDocument\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"documentContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"summaryInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawSummary\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"summaryContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"german\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"documentInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawDocument\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"documentContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"summaryInformation\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"rawSummary\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                },\n",
    "                                \"summaryContent\": {\n",
    "                                    \"type\": \"keyword\",\n",
    "                                    \"ignore_above\": 256\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return esMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_create(esIndex, indexName, esMapping):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Creation of the Index if not present in the cluster\n",
    "    # \n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       esIndex: ElasticSearch or OpenSearch connection\n",
    "    #       indexName: Name of the index that needs to be created\n",
    "    #       esMapping: Mapping of the index that needs to be created\n",
    "    # \n",
    "    #  Output:\n",
    "    #       If the index is already present then the function wont take any action\n",
    "    #       And if the index is not present then it will be created by the function\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    searchIndex = esIndex.indices.exists(index=indexName)\n",
    "\n",
    "    if searchIndex == False:\n",
    "        esIndex.indices.create(index=indexName, ignore=[400,404], body=esMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_insert(esIndex, indexName, celexInformation):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Insert the document in the ElasticSearch or OpenSearch Index\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       esIndex: ElasticSearch or OpenSearch connection\n",
    "    #       indexName: Name of the index that needs to be created\n",
    "    #       celexInformation: Information that needs to be inserted in the Index in JSON format\n",
    "    # \n",
    "    #  Output:\n",
    "    #       Insert the information in the ElasticSearch or OpenSearch Index keeping unqiue ID (_id) as the celex number\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    for id in range(len(celexInformation)):\n",
    "        doc = { \n",
    "                \"english\":\n",
    "                { \n",
    "                    \"documentInformation\":\n",
    "                        {\n",
    "                            \"rawDocument\":celexInformation[id]['EN']['documentInformation']['rawDocument'],\n",
    "                            \"documentContent\":celexInformation[id]['EN']['documentInformation']['documentContent']\n",
    "                        },\n",
    "\n",
    "                    \"summaryInformation\":\n",
    "                        {\n",
    "                            \"rawSummary\":celexInformation[id]['EN']['summaryInformation']['rawSummary'],\n",
    "                            \"summaryContent\":celexInformation[id]['EN']['summaryInformation']['summaryContent']\n",
    "                        }\n",
    "                },\n",
    "                \"german\":\n",
    "                { \n",
    "                    \"documentInformation\":\n",
    "                        {\n",
    "                            \"rawDocument\":celexInformation[id]['DE']['documentInformation']['rawDocument'],\n",
    "                            \"documentContent\":celexInformation[id]['DE']['documentInformation']['documentContent']\n",
    "                        },\n",
    "\n",
    "                    \"summaryInformation\":\n",
    "                        {\n",
    "                            \"rawSummary\":celexInformation[id]['DE']['summaryInformation']['rawSummary'],\n",
    "                            \"summaryContent\":celexInformation[id]['DE']['summaryInformation']['summaryContent']\n",
    "                        }\n",
    "                }\n",
    "            }\n",
    "        _id = celexInformation[id]['_id']\n",
    "        \n",
    "        retries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                esIndex.index(index=indexName,body=doc,id=_id)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if retries == 5:\n",
    "                    print('Indexing user \\'{}\\' failed for 5 consecutiv times. Aborting!'.format(_id))\n",
    "                    break\n",
    "                retries += 1\n",
    "                sleep(retries * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_existing_check(esIndex, indexName, celexList):\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    # Functionality: Check if the document is already present in the index\n",
    "    #\n",
    "    # Signature of the function:\n",
    "    #  Input: \n",
    "    #       esIndex: ElasticSearch or OpenSearch connection\n",
    "    #       indexName: Name of the index that needs to be created\n",
    "    #       celexList: List of the celex number for which the summary and content needs to be extracted\n",
    "    # \n",
    "    #  Output:\n",
    "    #       nonExisting: List of all the celex number that are not present in the ElasticSearch or OpenSearch index\n",
    "    # \"\"\"\"\"\"\"\"\"\"\n",
    "    nonExisting = []\n",
    "    for celexId in celexList:\n",
    "        document_status = esIndex.exists(index= indexName, id= celexId)\n",
    "        if document_status == False:\n",
    "            nonExisting.append(celexId)\n",
    "    \n",
    "    return nonExisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException(401, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-74f8c01025d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mesIndexMapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melastic_search_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0melastic_search_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesIndexMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Calling the Function for the given CELEX_Numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-96982dcae1a1>\u001b[0m in \u001b[0;36melastic_search_create\u001b[0;34m(esIndex, indexName, esMapping)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0melastic_search_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msearchIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mesIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msearchIndex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mesIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m404\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mesMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/opensearchpy/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/opensearchpy/client/indices.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, index, params, headers)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty value passed for a required argument 'index'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         return self.transport.perform_request(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/opensearchpy/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    405\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/opensearchpy/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 status, headers_response, data = connection.perform_request(\n\u001b[0m\u001b[1;32m    369\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             )\n\u001b[0;32m--> 275\u001b[0;31m             self._raise_error(\n\u001b[0m\u001b[1;32m    276\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/opensearchpy/connection/base.py\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data, content_type)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Undecodable raw error response from server: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         )\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException(401, '')"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Configuring the File name to logging Level\n",
    "    logging.basicConfig(filename=extraction_logs,level=logging.INFO)\n",
    "\n",
    "    listCelexNumber = pd.DataFrame(data=None)\n",
    "    celexInformation = pd.DataFrame(data=None)\n",
    "\n",
    "    # Input from the User:\n",
    "    # URL of the Domain specific Legal Acts, for example: Energy, Agriculture, Taxation, and other\n",
    "    # For Example:\n",
    "    #   1. From Legal Acts: https://eur-lex.europa.eu/browse/directories/legislation.html\n",
    "    #   2. If Legal Acts for Energy Domain is required\n",
    "    #   3. Provided URl will be: https://eur-lex.europa.eu/search.html?type=named&name=browse-by:legislation-in-force&CC_1_CODED=12&displayProfile=allRelAllConsDocProfile\n",
    "\n",
    "    providedUrl = input('Provide the URL: ')\n",
    "\n",
    "    startTime = time()\n",
    "    logging.info(\"Current date and time: \" + str(startTime))\n",
    "\n",
    "    # Elastic Search Index\n",
    "    indexName = input('Provide the Elastic Search Index Name: ')\n",
    "\n",
    "    while True:  \n",
    "        # Instance of Elastic Search\n",
    "        server = input('Server of the Elastic Search Index (localhost or Uniheidelberg): ')\n",
    "        if server.lower() == \"localhost\":\n",
    "            es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "            break\n",
    "        elif server.lower() == \"uniheidelberg\":\n",
    "            userName = input('University Heidelberg Elastic Search Username: ')\n",
    "            password = input('University Heidelberg Elastic Search Password: ')\n",
    "            es = OpenSearch(hosts = [{'host': 'elastic-dbs.ifi.uni-heidelberg.de', 'port': 443}], \n",
    "            http_auth =(userName, password), \n",
    "            use_ssl = True,\n",
    "            verify_certs = True,\n",
    "            ssl_assert_hostname = False,\n",
    "            ssl_show_warn = False\n",
    "            )\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    esIndexMapping = elastic_search_mapping()\n",
    "    elastic_search_create(es, indexName, esIndexMapping)\n",
    "    \n",
    "    # Calling the Function for the given CELEX_Numbers\n",
    "    listCelexNumber = celex_main(providedUrl)\n",
    "\n",
    "    nonExistingCelexNumber = elastic_search_existing_check(es, indexName, listCelexNumber)\n",
    "\n",
    "    # Calling the Function to extract the metadata for the list of celex numbers\n",
    "    celexInformation = get_document_information(nonExistingCelexNumber)\n",
    "\n",
    "    elastic_search_insert(es, indexName, celexInformation)\n",
    "\n",
    "    endTime = time()\n",
    "    logging.info(\"Current date and time: \" + str(endTime))\n",
    "    logging.info(\"Time for Execution of Script: \" + str(startTime - endTime))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
